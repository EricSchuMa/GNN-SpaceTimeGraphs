INFO:root:Namespace(batch_size=16, bottleneck_channels=128, cd=6, convolution_operator='GlobalSLC', cs=6, dropout=0.1, dropout_att=0.5, forecast_horizon=[3], gpu=True, h_batch_size=None, h_bottleneck_channels=None, h_dropout=None, h_dropout_att=None, h_lr=None, h_spatial_channels=None, hidden_state_size=264, k=8, learnable_l=True, log_file='./studies/global-slc.log', lr=0.001, mode='train', model='P3D', model_name='GlobalSLC', my_config='./configs/global-slc.yml', n_epochs=30, n_hid=100, n_trials=100, nclass=1, nhid_multipliers=None, num_features=2, num_nodes=207, num_units=1000, pickled_files='metr_la/adj_mx_la.pkl', save_model=True, seq_len=12, spatial_channels=96, test_file='./data/metr_la/test_sts.npz', toy_data=False, train_file='./data/metr_la/train_sts.npz', val_file='./data/metr_la/val_sts.npz', weight_decay=0.95)
INFO:__main__:epoch: 0
INFO:__main__:Mean train-loss over batch: 145.1845
INFO:__main__:Mean validation-loss over batch: 88.3208
INFO:__main__:Save model to path on epoch 0
INFO:__main__:epoch: 1
INFO:__main__:Mean train-loss over batch: 82.5360
INFO:__main__:Mean validation-loss over batch: 82.6075
INFO:__main__:Save model to path on epoch 1
INFO:__main__:epoch: 2
INFO:__main__:Mean train-loss over batch: 75.9572
INFO:__main__:Mean validation-loss over batch: 85.4503
INFO:__main__:epoch: 3
INFO:__main__:Mean train-loss over batch: 76.8339
INFO:__main__:Mean validation-loss over batch: 89.0698
INFO:__main__:epoch: 4
INFO:__main__:Mean train-loss over batch: 72.5896
INFO:__main__:Mean validation-loss over batch: 79.5464
INFO:__main__:Save model to path on epoch 4
INFO:__main__:epoch: 5
INFO:__main__:Mean train-loss over batch: 70.9602
INFO:__main__:Mean validation-loss over batch: 81.8790
INFO:__main__:epoch: 6
INFO:__main__:Mean train-loss over batch: 69.4850
INFO:__main__:Mean validation-loss over batch: 460191.6577
INFO:__main__:epoch: 7
INFO:__main__:Mean train-loss over batch: 68.7104
INFO:__main__:Mean validation-loss over batch: 88.7965
INFO:__main__:epoch: 8
INFO:__main__:Mean train-loss over batch: 68.6650
INFO:__main__:Mean validation-loss over batch: 93.0247
INFO:__main__:epoch: 9
INFO:__main__:Mean train-loss over batch: 80.5877
INFO:__main__:Mean validation-loss over batch: 80.8737
INFO:__main__:epoch: 10
INFO:__main__:Mean train-loss over batch: 70.2515
INFO:__main__:Mean validation-loss over batch: 83.8641
INFO:__main__:epoch: 11
INFO:__main__:Mean train-loss over batch: 69.6183
INFO:__main__:Mean validation-loss over batch: 80.8170
INFO:__main__:epoch: 12
INFO:__main__:Mean train-loss over batch: 66.2813
INFO:__main__:Mean validation-loss over batch: 82.3334
INFO:__main__:epoch: 13
INFO:__main__:Mean train-loss over batch: 70.0847
INFO:__main__:Mean validation-loss over batch: 80.8065
INFO:__main__:epoch: 14
INFO:__main__:Mean train-loss over batch: 69.8810
INFO:__main__:Mean validation-loss over batch: 86.1866
INFO:__main__:epoch: 15
INFO:__main__:Mean train-loss over batch: 66.2731
INFO:__main__:Mean validation-loss over batch: 82.5514
INFO:__main__:epoch: 16
INFO:__main__:Mean train-loss over batch: 65.5114
INFO:__main__:Mean validation-loss over batch: 103.4960
INFO:__main__:epoch: 17
INFO:__main__:Mean train-loss over batch: 65.9975
INFO:__main__:Mean validation-loss over batch: 82.9228
INFO:__main__:epoch: 18
INFO:__main__:Mean train-loss over batch: 72.2374
INFO:__main__:Mean validation-loss over batch: 91.2034
INFO:__main__:epoch: 19
INFO:__main__:Mean train-loss over batch: 75.3803
INFO:__main__:Mean validation-loss over batch: 87.0249
INFO:__main__:epoch: 20
INFO:__main__:Mean train-loss over batch: 82.6189
INFO:__main__:Mean validation-loss over batch: 91.3992
INFO:__main__:epoch: 21
INFO:__main__:Mean train-loss over batch: 75.5504
INFO:__main__:Mean validation-loss over batch: 4155355.2594
INFO:__main__:epoch: 22
INFO:__main__:Mean train-loss over batch: 70.9605
INFO:__main__:Mean validation-loss over batch: 4097148.0279
INFO:__main__:epoch: 23
INFO:__main__:Mean train-loss over batch: 69.1165
INFO:__main__:Mean validation-loss over batch: 87.2231
INFO:__main__:epoch: 24
INFO:__main__:Mean train-loss over batch: 69.8105
INFO:__main__:Mean validation-loss over batch: 84.3862
INFO:__main__:epoch: 25
INFO:__main__:Mean train-loss over batch: 68.9575
INFO:__main__:Mean validation-loss over batch: 80.2526
INFO:__main__:epoch: 26
INFO:__main__:Mean train-loss over batch: 65.7463
INFO:__main__:Mean validation-loss over batch: 87.7247
INFO:__main__:epoch: 27
INFO:__main__:Mean train-loss over batch: 66.1153
INFO:__main__:Mean validation-loss over batch: 83.4720
INFO:__main__:epoch: 28
INFO:__main__:Mean train-loss over batch: 70.6976
INFO:__main__:Mean validation-loss over batch: 85.9072
INFO:__main__:epoch: 29
INFO:__main__:Mean train-loss over batch: 66.9176
INFO:__main__:Mean validation-loss over batch: 83.7432
INFO:root:Namespace(batch_size=16, bottleneck_channels=128, cd=6, convolution_operator='GlobalSLC', cs=6, dropout=0.1, dropout_att=0.5, forecast_horizon=[3], gpu=True, h_batch_size=None, h_bottleneck_channels=None, h_dropout=None, h_dropout_att=None, h_lr=None, h_spatial_channels=None, hidden_state_size=264, k=8, learnable_l=True, log_file='./studies/global-slc.log', lr=0.001, mode='test', model='P3D', model_name='GlobalSLC', my_config='./configs/global-slc.yml', n_epochs=30, n_hid=100, n_trials=100, nclass=1, nhid_multipliers=None, num_features=2, num_nodes=207, num_units=1000, pickled_files='metr_la/adj_mx_la.pkl', save_model=True, seq_len=12, spatial_channels=96, test_file='./data/metr_la/test_sts.npz', toy_data=False, train_file='./data/metr_la/train_sts.npz', val_file='./data/metr_la/val_sts.npz', weight_decay=0.95)
INFO:__main__:Iterate over the test-split...
INFO:__main__:Mean loss over test dataset: 104.8828
